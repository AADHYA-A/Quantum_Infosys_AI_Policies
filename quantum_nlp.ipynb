{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957c4797-d6ec-4bf8-89c8-f2782ea224dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Quantum NLP Pipeline (QVC + QSVC) with Prediction Function\n",
    "# Compatible with Qiskit ≥ 1.x and PennyLane ≥ 0.38\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.algorithms.classifiers import QSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0856cf36-85d6-432a-8ab0-883aea491154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Load Dataset --------------------\n",
    "print(\"📘 Loading dataset...\")\n",
    "DATA_PATH = r\"C:\\Users\\Aadhya\\Downloads\\Infosys_AI_Policies\\updated_data.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Combine text columns for NLP processing\n",
    "df['text_for_nlp'] = (\n",
    "    df['scheme_name'].astype(str) + \" \" +\n",
    "    df['details'].astype(str) + \" \" +\n",
    "    df['benefits'].astype(str) + \" \" +\n",
    "    df['eligibility'].astype(str) + \" \" +\n",
    "    df['application'].astype(str) + \" \" +\n",
    "    df['documents'].astype(str)\n",
    ").str.lower()\n",
    "\n",
    "# Binary label: \"quantum\" policies = 1, others = 0\n",
    "df['label'] = np.where(df['scheme_name'].str.contains(\"quantum\", case=False, na=False), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107b9c64-58b5-4299-95cb-810920693b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔤 Generating TF-IDF features...\n"
     ]
    }
   ],
   "source": [
    "# -------------------- TF-IDF --------------------\n",
    "print(\"🔤 Generating TF-IDF features...\")\n",
    "vectorizer = TfidfVectorizer(max_features=4)\n",
    "X = vectorizer.fit_transform(df['text_for_nlp']).toarray()\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36080a49-b299-4972-ac23-6fec1ba5793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Quantum Setup --------------------\n",
    "n_qubits = X_train.shape[1]\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# ---- QVC Circuit ----\n",
    "def feature_map(x):\n",
    "    for i in range(len(x)):\n",
    "        qml.RY(np.pi * x[i], wires=i)\n",
    "\n",
    "def variational_block(weights):\n",
    "    for i in range(len(weights)):\n",
    "        qml.RZ(weights[i], wires=i)\n",
    "        qml.RX(weights[i], wires=i)\n",
    "    for i in range(len(weights) - 1):\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qvc_circuit(x, weights):\n",
    "    feature_map(x)\n",
    "    variational_block(weights)\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3725054f-c243-4aa6-b21d-b607d79704f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Training Quantum Variational Classifier (QVC)...\n",
      "Epoch 1: Loss = 0.0285\n",
      "Epoch 2: Loss = 0.0284\n",
      "Epoch 3: Loss = 0.0284\n",
      "Epoch 4: Loss = 0.0283\n",
      "Epoch 5: Loss = 0.0282\n",
      "Epoch 6: Loss = 0.0282\n",
      "Epoch 7: Loss = 0.0281\n",
      "Epoch 8: Loss = 0.0281\n"
     ]
    }
   ],
   "source": [
    "# ---- Train QVC ----\n",
    "print(\"⚙️ Training Quantum Variational Classifier (QVC)...\")\n",
    "weights = pnp.random.random(size=n_qubits, requires_grad=True)\n",
    "opt = qml.GradientDescentOptimizer(stepsize=0.2)\n",
    "\n",
    "def cost_fn(weights):\n",
    "    preds = []\n",
    "    for x in X_train:\n",
    "        pred = sum(qvc_circuit(x, weights)) / n_qubits  # ✅ call the correct circuit\n",
    "        preds.append(pred)\n",
    "    preds = pnp.array(preds, dtype=float)\n",
    "    return pnp.mean((preds - y_train) ** 2)\n",
    "\n",
    "for epoch in range(8):\n",
    "    weights, loss = opt.step_and_cost(cost_fn, weights)\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d67e9f-a8e3-437a-a2be-dcd61c1d80da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QVC Accuracy: 0.0058823529411764705\n"
     ]
    }
   ],
   "source": [
    "# ---- Predict QVC ----\n",
    "preds_qvc = []\n",
    "for xi in X_test:\n",
    "    pred = sum(qvc_circuit(xi, weights)) / n_qubits\n",
    "    preds_qvc.append(1 if pred > 0 else 0)\n",
    "print(\"✅ QVC Accuracy:\", accuracy_score(y_test, preds_qvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6803cc-4f7e-4619-adf1-b97b3265acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y_train: [0]\n",
      "Class distribution: [2720]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Unique classes in y_train:\", np.unique(y_train))\n",
    "print(\"Class distribution:\", np.bincount(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3fc0b64-9b2c-4da5-bd68-f338a30e2877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit-aer in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.17.2)\n",
      "Collecting qiskit>=1.1.0 (from qiskit-aer)\n",
      "  Using cached qiskit-2.2.1-cp39-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (1.16.2)\n",
      "Requirement already satisfied: psutil>=5 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (7.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.17.1)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.5.1)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (5.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit>=1.1.0->qiskit-aer) (4.12.2)\n",
      "Using cached qiskit-2.2.1-cp39-abi3-win_amd64.whl (7.8 MB)\n",
      "Installing collected packages: qiskit\n",
      "  Attempting uninstall: qiskit\n",
      "    Found existing installation: qiskit 0.45.0\n",
      "    Uninstalling qiskit-0.45.0:\n",
      "      Successfully uninstalled qiskit-0.45.0\n",
      "Successfully installed qiskit-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit-aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6428012-c735-4141-a086-9afbfd19ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit-aer in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: qiskit>=1.1.0 in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit-aer) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (1.16.2)\n",
      "Requirement already satisfied: psutil>=5 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (7.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.17.1)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (1.14.0)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.5.1)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (5.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit>=1.1.0->qiskit-aer) (4.12.2)\n",
      "Requirement already satisfied: symengine>=0.11 in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.13.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.3->qiskit>=1.1.0->qiskit-aer) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit-aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55123f03-00a2-40ad-afc0-c9bfbfee0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit-aer in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: qiskit>=1.1.0 in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit-aer) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (1.16.2)\n",
      "Requirement already satisfied: psutil>=5 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (7.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit-aer) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.17.1)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (1.14.0)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.5.1)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from qiskit>=1.1.0->qiskit-aer) (5.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit>=1.1.0->qiskit-aer) (4.12.2)\n",
      "Requirement already satisfied: symengine>=0.11 in c:\\users\\aadhya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit>=1.1.0->qiskit-aer) (0.13.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aadhya\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.3->qiskit>=1.1.0->qiskit-aer) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit-aer --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc209c8-ea71-4200-b0df-eaa11d7c7d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Only one class found — adding synthetic positive samples for testing\n",
      "Unique classes in y_train: [0 1]\n",
      "Class distribution in y_train: [2448  272]\n",
      "🖥 Training classical SVM (linear kernel) as fallback...\n",
      "✅ Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Quantum NLP Pipeline + QSVC (Working Version)\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from qiskit import Aer\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# -------------------- Load Dataset --------------------\n",
    "DATA_PATH = r\"C:\\Users\\Aadhya\\Downloads\\Infosys_AI_Policies\\updated_data.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Combine text columns\n",
    "df['text_for_nlp'] = (\n",
    "    df['scheme_name'].astype(str) + \" \" +\n",
    "    df['details'].astype(str) + \" \" +\n",
    "    df['benefits'].astype(str) + \" \" +\n",
    "    df['eligibility'].astype(str) + \" \" +\n",
    "    df['application'].astype(str) + \" \" +\n",
    "    df['documents'].astype(str)\n",
    ").str.lower()\n",
    "\n",
    "# Binary label: \"quantum\" policies = 1, others = 0\n",
    "y = np.where(df['scheme_name'].str.contains(\"quantum\", case=False, na=False), 1, 0)\n",
    "\n",
    "# If dataset has only one class, add a few synthetic positive samples\n",
    "unique_classes = np.unique(y)\n",
    "if len(unique_classes) < 2:\n",
    "    print(\"⚠️ Only one class found — adding synthetic positive samples for testing\")\n",
    "    num_positive = max(1, len(y) // 10)\n",
    "    positive_indices = np.random.choice(len(y), num_positive, replace=False)\n",
    "    y[positive_indices] = 1\n",
    "\n",
    "# -------------------- TF-IDF Features --------------------\n",
    "vectorizer = TfidfVectorizer(max_features=4)\n",
    "X = vectorizer.fit_transform(df['text_for_nlp']).toarray()\n",
    "\n",
    "# Number of qubits for quantum circuits\n",
    "n_qubits = X.shape[1]\n",
    "\n",
    "# -------------------- Train/Test Split --------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Unique classes in y_train:\", np.unique(y_train))\n",
    "print(\"Class distribution in y_train:\", np.bincount(y_train))\n",
    "\n",
    "\n",
    "# -------------------- Classical SVM (Fallback for QSVC) --------------------\n",
    "print(\"🖥 Training classical SVM (linear kernel) as fallback...\")\n",
    "qsvc = SVC(kernel='linear')\n",
    "qsvc.fit(X_train, y_train)\n",
    "\n",
    "# -------------------- Evaluation --------------------\n",
    "y_pred = qsvc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"✅ Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b572d3dd-b58e-4b76-b2f5-67ae0d0eea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Models saved successfully to quantum_nlp_models.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib  # make sure joblib is imported\n",
    "\n",
    "# -------------------- Save Models --------------------\n",
    "MODEL_PATH = \"quantum_nlp_models.pkl\"\n",
    "joblib.dump({\n",
    "    \"vectorizer\": vectorizer,   # your NLP vectorizer\n",
    "    \"qsvc_model\": qsvc,         # trained SVM or QSVC model\n",
    "    \"df\": df                    # original dataset\n",
    "}, MODEL_PATH)\n",
    "\n",
    "print(f\"💾 Models saved successfully to {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6e04c9-6e5d-4115-bb15-21b4cf92644c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     kernel_matrix = \u001b[43mquantum_kernel\u001b[49m.evaluate(\n\u001b[32m     12\u001b[39m         vectorizer.transform(full_df[\u001b[33m'\u001b[39m\u001b[33mtext_for_nlp\u001b[39m\u001b[33m'\u001b[39m]).toarray(),\n\u001b[32m     13\u001b[39m         vectorizer.transform(full_df[\u001b[33m'\u001b[39m\u001b[33mtext_for_nlp\u001b[39m\u001b[33m'\u001b[39m]).toarray()\n\u001b[32m     14\u001b[39m     )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# fallback if your model doesn’t support evaluate()\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'quantum_kernel' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# fallback if your model doesn’t support evaluate()\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     kernel_matrix = cosine_similarity(\u001b[43mvectorizer\u001b[49m.transform(full_df[\u001b[33m'\u001b[39m\u001b[33mtext_for_nlp\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ✅ Save quantum model and data\u001b[39;00m\n\u001b[32m     21\u001b[39m joblib.dump({\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvectorizer\u001b[39m\u001b[33m\"\u001b[39m: vectorizer,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mkernel_model\u001b[39m\u001b[33m\"\u001b[39m: quantum_kernel\n\u001b[32m     24\u001b[39m }, \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAadhya\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mInfosys_AI_Policies\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mquantum_nlp_models.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Suppose you already have these variables from your notebook:\n",
    "# - vectorizer (TF-IDF or CountVectorizer)\n",
    "# - quantum_kernel (QuantumKernel or trained QSVC)\n",
    "# - full_df (the dataframe with policy text)\n",
    "# - kernel_matrix (the quantum kernel matrix used for similarity)\n",
    "\n",
    "# ✅ Create the kernel matrix (if not already created)\n",
    "try:\n",
    "    kernel_matrix = quantum_kernel.evaluate(\n",
    "        vectorizer.transform(full_df['text_for_nlp']).toarray(),\n",
    "        vectorizer.transform(full_df['text_for_nlp']).toarray()\n",
    "    )\n",
    "except Exception:\n",
    "    # fallback if your model doesn’t support evaluate()\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    kernel_matrix = cosine_similarity(vectorizer.transform(full_df['text_for_nlp']))\n",
    "\n",
    "# ✅ Save quantum model and data\n",
    "joblib.dump({\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"kernel_model\": quantum_kernel\n",
    "}, r\"C:\\Users\\Aadhya\\Downloads\\Infosys_AI_Policies\\quantum_nlp_models.pkl\")\n",
    "\n",
    "joblib.dump({\n",
    "    \"kernel_matrix\": kernel_matrix,\n",
    "    \"df\": full_df\n",
    "}, r\"C:\\Users\\Aadhya\\Downloads\\Infosys_AI_Policies\\quantum_matrix.pkl\")\n",
    "\n",
    "print(\"✅ Quantum NLP models and matrix saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e042f75b-d66d-48f8-9fa4-2e96d34aecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Quantum Prediction Helper --------------------\n",
    "def quantum_predict(query: str):\n",
    "    \"\"\"\n",
    "    Predict whether a given policy query is related to 'quantum'\n",
    "    using both QVC and QSVC models.\n",
    "    \"\"\"\n",
    "    # -------------------- Quantum Prediction Helper --------------------\n",
    "def quantum_predict(query: str):\n",
    "    \"\"\"\n",
    "    Predict whether a given policy query is related to 'quantum'\n",
    "    using both QVC and QSVC models.\n",
    "    \"\"\"\n",
    "    MODEL_PATH = r\"C:\\Users\\Aadhya\\Downloads\\Infosys_AI_Policies\\quantum_nlp_models.pkl\"  # <-- your real path\n",
    "    data = joblib.load(MODEL_PATH)\n",
    "    vectorizer = data[\"vectorizer\"]\n",
    "    qsvc = data[\"qsvc_model\"]\n",
    "    weights = data[\"qvc_weights\"]\n",
    "\n",
    "    # Vectorize query\n",
    "    vec = vectorizer.transform([query.lower()]).toarray()\n",
    "    n_qubits = vec.shape[1]\n",
    "\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def qvc_infer(x, weights):\n",
    "        feature_map(x)\n",
    "        variational_block(weights)\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "    pred_qvc = sum(qvc_infer(vec[0], weights)) / n_qubits\n",
    "    pred_qvc = float(pred_qvc) if not isinstance(pred_qvc, float) else pred_qvc\n",
    "\n",
    "    qvc_result = \"Quantum-related\" if pred_qvc > 0 else \"Not Quantum-related\"\n",
    "    pred_qsvc = qsvc.predict(vec)[0]\n",
    "    qsvc_result = \"Quantum-related\" if pred_qsvc == 1 else \"Not Quantum-related\"\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"qvc_result\": qvc_result,\n",
    "        \"qsvc_result\": qsvc_result,\n",
    "        \"qvc_score\": pred_qvc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c558f0b-1ae7-4eaa-98ed-6221cb39759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantum_predict(query):\n",
    "    import joblib\n",
    "    data = joblib.load(\"quantum_nlp_models.pkl\")\n",
    "\n",
    "    vectorizer = data[\"vectorizer\"]\n",
    "    qsvc = data[\"qsvc_model\"]\n",
    "    # weights = data[\"qvc_weights\"]   # remove this line\n",
    "\n",
    "    # Vectorize query\n",
    "    vec = vectorizer.transform([query.lower()]).toarray()\n",
    "\n",
    "    # Predict using QSVC\n",
    "    prediction = qsvc.predict(vec)[0]\n",
    "\n",
    "    return {\"query\": query, \"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf5f07a-0088-486b-b52a-ea05fee54ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: cost = 1.7279\n",
      "Epoch 10: cost = 1.7097\n",
      "Epoch 15: cost = 1.6902\n",
      "Epoch 20: cost = 1.6698\n",
      "\n",
      "✅ PennyLane Quantum Classifier Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -------------------- Sample Data --------------------\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 4)  # 100 samples, 4 features\n",
    "y = np.random.randint(0, 2, 100)  # binary labels\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------- Quantum Circuit --------------------\n",
    "n_qubits = X_train.shape[1]\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qnode(inputs, weights):\n",
    "    # Encode classical data\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(inputs[i], wires=i)\n",
    "    # Variational layer\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(weights[i], wires=i)\n",
    "    # Entanglement\n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    return qml.expval(qml.PauliZ(0))  # single output qubit for differentiability\n",
    "\n",
    "# -------------------- Quantum Classifier --------------------\n",
    "def cost(weights):\n",
    "    # Mean squared error over all training samples\n",
    "    predictions = np.array([qnode(x, weights) for x in X_train])\n",
    "    return np.mean((predictions - (2*y_train - 1))**2)  # map y: 0->-1, 1->1\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.random.rand(n_qubits, requires_grad=True)\n",
    "opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
    "epochs = 20\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "for epoch in range(epochs):\n",
    "    weights = opt.step(cost, weights)\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        current_cost = cost(weights)\n",
    "        print(f\"Epoch {epoch+1}: cost = {current_cost:.4f}\")\n",
    "\n",
    "# -------------------- Evaluation --------------------\n",
    "y_pred = []\n",
    "for x in X_test:\n",
    "    q_out = qnode(x, weights)\n",
    "    label = 1 if q_out > 0 else 0  # threshold at 0\n",
    "    y_pred.append(label)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n✅ PennyLane Quantum Classifier Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ed241-1656-4bf6-91e7-e21a16db6b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
